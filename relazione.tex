\documentclass{article}

\usepackage{bbm}
\usepackage{amsmath}

\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}

\title{LCDP - Codici correttori}
\date{14 febbraio 2018}
\author{Saftoiu Vlad Alexandru}

\begin{document}
	\pagenumbering{gobble}
	\maketitle
	\newpage
	\pagenumbering{arabic}

	\tableofcontents
	\newpage


	\section{Traccia}
	\begin{enumerate}
		\item introduzione/descrizione LDPC (e brevissima storia?)
		\item check matrix sparsa 
		\item sum-product algorithm
		\item factor graph
		\item esempi concreti di impiego di codici correttori LDPC
	\end{enumerate}

	\section{Introduzione}
	Un codice LDPC è un codice a blocchi con una matriche di controllo $\textbf{H}$ sparsa ovvero con "pochi" uno su ogni riga e su ogni colonna. Un codice a blocchi è regolare quando, data una matrice $H \in M_{m \times n}$ elementi in $\left\{0,1\right\}$ si ha che:
	\begin{equation}
		  \forall j =1 ... n \quad W_{ham}(H^j) = J 
	\end{equation}
	\begin{equation}
		\forall i = 1 ... m \quad W_{ham}(H_i) = K
	\end{equation}
	Un codice LDPC è un codice ottimo con una buona distanza, a patto di riuscire a costruire un decoder efficiente che, dato l'output $\textbf{r}$ sul canale C, individua la codeword $\textbf{t}$ con la probabilità $P(\textbf{r}|\textbf{t})$ maggiore. Decodificare un codice LDPC è un problema NP-completo, un approcio che possiamo seguire per ottenere un decoder è dato dall'utilizzo dell'algoritmo somme-prodotti a scambio di messaggi.
	\subsection{Esempio}
	Esempio di una matrice per un codice a blocchi generato casualmente con i seguenti paramentri:
	\begin{itemize}
		\item lunghezza blocchi $N = 16$
		\item peso colonne $J  = 3$
		\item peso righe $K = 4$
	\end {itemize}
	La matrice risultante è $H \in M_{12 \times 16}$ elementi in $\left\{0,1\right\}$
	\begin{equation*}
		\begin{smallmatrix}
			1& & & & & &1& &1&1& & & & & &  \\
			 &1& & & &1& &1& & &1& & & & &  \\
			1& & & & & & & &1&1& &1& & & &  \\
			 & & &1& &1& & & & & &1&1& & &  \\
			 &1& & &1& & & & & & &1&1& & &  \\
			 &1& & & & &1& & &1& & &1& & &  \\
			 & & &1& & & &1& & & & & &1& &1 \\
			 & & & &1& & & &1& &1& & &1& &  \\
			 & &1&1& & &1& & & & & & &1& &  \\
			1& & & &1& & & & & & & & & &1&1 \\
			 & &1& & &1& & & & & & & & &1&1 \\
			 & &1& & & & &1& & &1& & & &1& 
		\end{smallmatrix}
	\end{equation*}
	Concettualmente ciascuno degli $n$ bit partecipa a $J = 3$ degli $m$ checks, mentre ciascuno degli $m$ checks effettua la somma di $K = 4$ bits collegati.
	Graficamente possiamo rappresentare la matrice di controllo come un grafo bipartito, da una parte tutti i bits e dall'altra tutti i checks.
	\textbf{INSERT FACTOR GRAPH}
	
	
	\section{Factor graph}
		Un \textit{factor graph} è un grafo bipartito che rappresenta la fattorizzazione di una funzione, in particolare viene utilizzato per rappresentare i fattori di una distribuzione di probabilità. In un \textit{factor graph} un fattore che è $0$ oppure $1$ viene chiamato \textit{constraint}.


	\section{Algoritmo somme-prodotti a scambio di messaggi}
Anche conosciuto come \textit{propagation-belief algorithm}, è un algoritmo utilizzato per fare inferenza sulle strutture ad albero (ed in maniera approssimata anche sui grafi) calcolando le probabilità marginali di un modello grafico con N variabili $\bar{x} = (x_1,x_2, ..., x_N)$ a valori su un alfabeto finito $\mathcal{X}$.
Obiettivo: trovare $\textbf{x}$ che massimizza:
\begin{equation} 
	P^*(\textbf{x})=P(\textbf{x})\mathbbm{1}[\textbf{Hx} = \textbf{z}]
\end{equation}
Ci interessa calcolare la probabilità a posteriori $P(x_n = 1 | \textbf{z}, \textbf{H})$ per ogni bit $x_n$. Nel grafo rappresentante la \textit{parity-check matrix} del nostro codice sono però presenti molti cicli che ci porterebbero a non utilizzare l'algoritmo somme-prodotti per calcolare le probabilità (i risultati sarebbero imprecisi), tuttavia nell'ottica di decodificare la corretta \textit{codeword} non siamo interessati all'esattezza delle probabilità. Il problema da risolvere per la decodifica è trovare 
\begin{equation}
\textbf{Hx} = \textbf{0}  mod_2
\end{equation}
	\subsection{Iterazione dell'algoritmo}
	\subsubsection{Terminologia}
	\begin{itemize}
		\item $\mathcal{N}(m) := \left\{ n | H_{mn} = 1 \right\}$ l'insieme degli indici di colonna che hanno uno alla riga m.
		\item $\mathcal{M}(n) := \left\{ m | H_{mn} = 1 \right\}$ l'insieme degli indici di riga che hanno uno alla colonna n.
		\item $\mathcal{M}(n)\setminus n$ rappresenta l'esclusione del bit n dall'insieme
		\item $p_n^0 = P(x_n=0)$ probabilità a priori che il bit $x_n$ sià uguale a 0
		\item $p_n^1 = P(x_n=1)=1-p_n^0$ probabilità a priori che il bit $x_n$ sià uguale a 1
		\item $q^x_{mn}$ è la probabilità che il bit $n$ di $\textbf{x}$ abbia il valore $x$
		\item $r^x_{mn}$ è la probabilità che il check $m$ sia "soddisfatto" se il bit $n$ di $\textbf{x}$ abbia il valore fissato su $x$ e gli altri bits hanno una distribuzione separabile data dalle probabilità $\left\{ q_{mn'} | n' \in \mathcal{N}(m)\setminus n\right\}$
	\end{itemize}
	\subsubsection{Init}
	Ciascun elemento $H_{mn} = 1$ mi permette di impostare il corrispondente $q^0_{mn} = p^0_n$ e $q^1_{mn} = p^1_n$
	\subsubsection{Progressione orizzontale}
	Cicliamo i checks $m$ e calcoliamo per ogni $n \in \mathcal{N}(m)$ due probabilità:
	\begin{itemize}
		\item $r^0_{mn}$ ovvero la probabilità di osservare il bit $z_m$ dato che $x_n =0$
		\item $r^1_{mn}$ cioè la probabilità di osservare il bit $z_m$ ha dato che $x_n =1$
	\end{itemize}
	Se consideriamo:
	\begin{itemize}
		\item $\mathcal{N}'(m)=\left\{n' \in \mathcal{N}(m)| n' \neq n\right\} = \mathcal{N}(m) \setminus n$
		\item $\mathcal{G}=\left\{x_{n'} | \quad n' \in \mathcal{N}'(m) \right\}$ 
		\item $v \in \left\{0,1\right\}$
	\end{itemize}
	allora le due probabilità si possono esprimere come segue:
	\begin{equation}
		r^v_{mn}= \sum_{g \in \mathcal{G}} P(z_m|x_n = v, \mathcal{G}) \prod_{n' \in \mathcal{N}'(m)} q^{x_{n'}}_{mn'}
	\end{equation}
	Esempio per: $n' \in \mathcal{N}'(m)$ (bits che partecipano al check $m$ escluso il bit $n$). Se il check $m$ è la somma dei bit $x_1, x_5, x_7, x_{12}$ allora $\mathcal{N}(m) = \left\{ 1,5,7,12\right\}$ e la produttoria che compare nella formula 5 diventa $q_{m,1}^{x_1} \times q_{m, 7}^{x_7} \times q_{m,12}^{x_{12}}$  
	\subsubsection{Progressione verticale}
	La progressione verticale aggiorna le probabilità $q^v_{mn}$ con i valori calcolati di $r^v_{mn}$, ovvero per ogni $n$ si calcola (con $v \in \left\{0,1\right\}$):
	\begin{equation}
		q^v_{mn} = \alpha_{mn} p^v_n \prod_{m' \in \mathcal{M}(n)\setminus m} r^v_{m'n}
	\end{equation}
	\begin{equation}
		q^v_{n} = \alpha_{n} p^v_n \prod_{m \in \mathcal{M}(n)} r^v_{mn}
	\end{equation}
	con $q^v_{n}$ rappresentante la pseudo-probabilità a posteriori per il bit $n$ di assumere il valore $v$ e viene utilizzata per il criterio di arresto, ricordando che stiamo cercando $\textbf{Hx}=\textbf{z}$ e che possiamo interrompere l'algoritmo per un $\hat{\textbf{x}}$ quando ci permette di decodificare correttamente la codeword.
	Dopo aver aggiornato le probabilità l'algoritmo prosegue con il movimento orizzontale.
	\subsubsection{Criterio di arresto}
	Quando $q^1_n >0.5$ per $x_n$ e $H\hat{\textbf{x}}=\textbf{z}$ possiamo interrompere, altrimenti è possibile procedere per altri $i$ iterazioni sollevando un eccezione qualora non si raggiunga un $\hat{\textbf{x}}$ soddisfacente.
	\subsubsection{Costi}
	\begin{itemize}
		\item \textbf{matrice H} - se bruteforce $\approx N^3$
		\item \textbf{codifica} - $\approx N^2$
		\item \textbf{decodifica} - $ \frac{6 \times i \times t}{R} $ a prescindere dalla lunghezza dei blocchi
	\end{itemize}
\end{document}